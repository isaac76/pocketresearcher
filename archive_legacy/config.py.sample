# PocketResearcher Configuration Template
# 
# SETUP INSTRUCTIONS:
# 1. Copy this file to config.py: cp config.py.sample config.py
# 2. Edit config.py to add your API keys or choose local models
# 3. The config.py file is automatically protected by .gitignore
#
# For local-only usage (no API keys needed):
# - Set DEFAULT_LLM = "phi2" or "gpt2"
# - Leave API keys as None or placeholder values

# LLM Configuration
# Options: "gemini", "phi2", "gpt2", "local"
DEFAULT_LLM = "gemini"

# LLM Configuration Dictionary
LLM_CONFIG = {
    "gemini": {
        "api_key": "GEMINI_API_KEY",
        "rate_limit": 15,
        "max_tokens": 100
    },
    "phi2": {
        "model_path": "microsoft/phi-2",
        "local": True,
        "max_tokens": 100
    },
    "gpt2": {
        "model_path": "gpt2",
        "local": True,
        "max_tokens": 100
    }
}

# API Keys (replace with your actual keys)
GEMINI_API_KEY = "YOUR_GEMINI_API_KEY_HERE"  # Get from https://aistudio.google.com/
OPENAI_API_KEY = None  # Add your OpenAI key if you have one

# Rate Limiting (requests per minute)
GEMINI_RATE_LIMIT = 15
OPENAI_RATE_LIMIT = 60

# Local Model Configuration
LOCAL_MODELS = {
    "phi2": "microsoft/phi-2",
    "gpt2": "gpt2",
    "gpt2-medium": "gpt2-medium",
    "gpt2-large": "gpt2-large"
}

# Default local model when API is unavailable
FALLBACK_LOCAL_MODEL = "phi2"

# Generation Parameters
MAX_TOKENS = 100
TEMPERATURE = 0.7

# Research Configuration
PROOF_GENERATION_FREQUENCY = 3  # Every N iterations
ENABLE_LEAN_TRANSLATION = True
ENABLE_RATE_LIMITING = True

# Logging
VERBOSE_OUTPUT = True
LOG_API_CALLS = False

# Instructions:
# 1. Copy this file to config.py
# 2. Replace YOUR_GEMINI_API_KEY_HERE with your actual Gemini API key
# 3. Optionally add other API keys as needed
# 4. Customize other settings as desired
